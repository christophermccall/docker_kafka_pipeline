
services:
  zookeeper:
    image: wurstmeister/zookeeper:latest
    ports:
      - "2181:2181"

  kafka:
    image: wurstmeister/kafka:latest
    ports:
      - "9092:9092"
    expose:
      - "9093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9093,OUTSIDE://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "customer_transactions:1:1"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  producer:
    build:
      context: .
      dockerfile: Dockerfile-producer
    depends_on:
      - kafka
    command: ["python3", "kafka_producer.py"]
    networks:
      - default


  mysql:
    image: mysql:8.0.31
    environment:
      - MYSQL_ROOT_PASSWORD=${rootpassword}
      - MYSQL_DATABASE=${customer_database}
      - MYSQL_USER=${user}
      - MYSQL_PASSWORD=${password}
    ports:
      - "3307:3306"
    volumes:
      - mysql-data:/var/lib/mysql

  spark:
    image: bitnami/spark:latest
    command: /opt/bitnami/spark/bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 /app/spark_process.py
    volumes:
      - ./spark_process.py:/app/spark_process.py

  flask:
    build:
      context: .
      dockerfile: Dockerfile-flask
    ports:
      - "5000:5000"
    environment:
      - AWS_ACCESS_KEY_ID=${access_key}
      - AWS_SECRET_ACCESS_KEY=${secret_access_key}
      - AWS_DEFAULT_REGION=${default_region}
    volumes:
      - .:/app
volumes:
  mysql-data:


